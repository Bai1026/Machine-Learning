{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guE34D3Fj2R9"
      },
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V57zhcTp1Xxb"
      },
      "source": [
        "Objectives:\n",
        "* Solve a regression problem with deep neural networks (DNN).\n",
        "* Understand basic DNN training tips.\n",
        "* Familiarize yourself with PyTorch.\n",
        "\n",
        "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUATI4ONArv_",
        "outputId": "0b4ac02d-3fb2-44eb-a9e1-f6ec0c646032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar  2 03:54:36 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    26W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check gpu type\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm2aXcb-j9Fc"
      },
      "source": [
        "# Download data\n",
        "If the Google Drive links below do not work, you can use the dropbox link below or download data from [Kaggle](https://www.kaggle.com/competitions/ml2023spring-hw1/overview), and upload data manually to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPmfl-awlKZA",
        "outputId": "61cb971e-ddfe-4c10-b66d-bd0155c9dae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-02 03:54:36--  https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/lmy1riadzoy0ahw/covid.train.csv [following]\n",
            "--2023-03-02 03:54:37--  https://www.dropbox.com/s/raw/lmy1riadzoy0ahw/covid.train.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc9cdcf06526902c9e8d76ab48aa.dl.dropboxusercontent.com/cd/0/inline/B3cgsG6rXGmDIbYZwbe4GCRLLSSBtU63tzkMJIidmDbaP2MtU16FaCvsGBKvQ1ZwAKBbEVAVfW5rLBhSifTcuR7MWKl0ghY1I-5Bb4LyxDJVGYITfv4g9vehcwMpyrIFu8QUD5PyvISA9j9YubLpoiwsc8FWVzREsaKAKy2FW4ULzQ/file# [following]\n",
            "--2023-03-02 03:54:37--  https://uc9cdcf06526902c9e8d76ab48aa.dl.dropboxusercontent.com/cd/0/inline/B3cgsG6rXGmDIbYZwbe4GCRLLSSBtU63tzkMJIidmDbaP2MtU16FaCvsGBKvQ1ZwAKBbEVAVfW5rLBhSifTcuR7MWKl0ghY1I-5Bb4LyxDJVGYITfv4g9vehcwMpyrIFu8QUD5PyvISA9j9YubLpoiwsc8FWVzREsaKAKy2FW4ULzQ/file\n",
            "Resolving uc9cdcf06526902c9e8d76ab48aa.dl.dropboxusercontent.com (uc9cdcf06526902c9e8d76ab48aa.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc9cdcf06526902c9e8d76ab48aa.dl.dropboxusercontent.com (uc9cdcf06526902c9e8d76ab48aa.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2162766 (2.1M) [text/plain]\n",
            "Saving to: ‘covid_train.csv’\n",
            "\n",
            "covid_train.csv     100%[===================>]   2.06M  6.73MB/s    in 0.3s    \n",
            "\n",
            "2023-03-02 03:54:38 (6.73 MB/s) - ‘covid_train.csv’ saved [2162766/2162766]\n",
            "\n",
            "--2023-03-02 03:54:38--  https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/zalbw42lu4nmhr2/covid.test.csv [following]\n",
            "--2023-03-02 03:54:38--  https://www.dropbox.com/s/raw/zalbw42lu4nmhr2/covid.test.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucf588c23eb2f80b5a1c0a2faaf3.dl.dropboxusercontent.com/cd/0/inline/B3ewi6VC-q9WIN1Qni7JohOBCE5Eh_09j0z4f8_nv8VaZHXuMyaJwIDtBYiDDw-pyaE735_jz_P6wO7DACplKpoTrpxXAvK2Fvl7z_OZo2cI5tkeQ9T4c1T-UIKleYWtE0-0M1CXHUzTzpxjXvxMoR_Zx36REDMsZgoYizjeUERzcQ/file# [following]\n",
            "--2023-03-02 03:54:39--  https://ucf588c23eb2f80b5a1c0a2faaf3.dl.dropboxusercontent.com/cd/0/inline/B3ewi6VC-q9WIN1Qni7JohOBCE5Eh_09j0z4f8_nv8VaZHXuMyaJwIDtBYiDDw-pyaE735_jz_P6wO7DACplKpoTrpxXAvK2Fvl7z_OZo2cI5tkeQ9T4c1T-UIKleYWtE0-0M1CXHUzTzpxjXvxMoR_Zx36REDMsZgoYizjeUERzcQ/file\n",
            "Resolving ucf588c23eb2f80b5a1c0a2faaf3.dl.dropboxusercontent.com (ucf588c23eb2f80b5a1c0a2faaf3.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to ucf588c23eb2f80b5a1c0a2faaf3.dl.dropboxusercontent.com (ucf588c23eb2f80b5a1c0a2faaf3.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 638359 (623K) [text/plain]\n",
            "Saving to: ‘covid_test.csv’\n",
            "\n",
            "covid_test.csv      100%[===================>] 623.40K  4.00MB/s    in 0.2s    \n",
            "\n",
            "2023-03-02 03:54:39 (4.00 MB/s) - ‘covid_test.csv’ saved [638359/638359]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# google drive link\n",
        "# !gdown --id '1BjXalPZxq9mybPKNjF3h5L3NcF7XKTS-' --output covid_train.csv\n",
        "# !gdown --id '1B55t74Jg2E5FCsKCsUEkPKIuqaY7UIi1' --output covid_test.csv\n",
        "\n",
        "# dropbox link\n",
        "!wget -O covid_train.csv https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\n",
        "!wget -O covid_test.csv https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igqIMEgu64-F"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xybQNYCXYu13"
      },
      "outputs": [],
      "source": [
        "# Numerical Operations\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# Reading/Writing Data\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# For Progress Bar\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Pytorch\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# For plotting learning curve\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTAVqRfc2KK3"
      },
      "source": [
        "# Some Utility Functions\n",
        "\n",
        "You do not need to modify this part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RbrcpfYN2I-H"
      },
      "outputs": [],
      "source": [
        "def same_seed(seed): \n",
        "    '''Fixes random number generator seeds for reproducibility.'''\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def train_valid_split(data_set, valid_ratio, seed):\n",
        "    '''Split provided training data into training set and validation set'''\n",
        "    valid_set_size = int(valid_ratio * len(data_set)) \n",
        "    train_set_size = len(data_set) - valid_set_size\n",
        "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
        "    return np.array(train_set), np.array(valid_set)\n",
        "\n",
        "def predict(test_loader, model, device):\n",
        "    model.eval() # Set your model to evaluation mode.\n",
        "    preds = []\n",
        "    for x in tqdm(test_loader):\n",
        "        x = x.to(device)                        \n",
        "        with torch.no_grad():                   \n",
        "            pred = model(x)                     \n",
        "            preds.append(pred.detach().cpu())   \n",
        "    preds = torch.cat(preds, dim=0).numpy()  \n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqO3lTm78nNO"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-mjaJM0wprMs"
      },
      "outputs": [],
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    '''\n",
        "    x: Features.\n",
        "    y: Targets, if none, do prediction.\n",
        "    '''\n",
        "    def __init__(self, x, y=None):\n",
        "        if y is None:\n",
        "            self.y = y\n",
        "        else:\n",
        "            self.y = torch.FloatTensor(y)\n",
        "        self.x = torch.FloatTensor(x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is None:\n",
        "            return self.x[idx]\n",
        "        else:\n",
        "            return self.x[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m73ooU75CL_j"
      },
      "source": [
        "# Neural Network Model\n",
        "Try out different model architectures by modifying the class below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qn97_WvvrEkG"
      },
      "outputs": [],
      "source": [
        "class My_Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(My_Model, self).__init__()\n",
        "        # TODO: modify model's structure, be aware of dimensions.\n",
        "        self.layers = nn.Sequential(\n",
        "            \n",
        "\n",
        "            # nn.Linear(input_dim, 500),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(500, 250),\n",
        "            # nn.ReLU(),\n",
        "            # # nn.Linear(input_dim, 32),\n",
        "            # # nn.ReLU(),\n",
        "            # nn.Linear(250,100),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(100, 1),\n",
        "            # nn.ReLU()\n",
        "\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8,1),\n",
        "            nn.ReLU()\n",
        "            \n",
        "\n",
        "            # nn.Linear(input_dim, 32),\n",
        "            # # nn.ReLU(),\n",
        "            # nn.SiLU(),\n",
        "            # nn.Linear(32, 16),\n",
        "            # # nn.ReLU(),\n",
        "            # nn.SiLU(),\n",
        "            # nn.Linear(16,1),\n",
        "            # # nn.ReLU()\n",
        "            # nn.SiLU()\n",
        "\n",
        "            # nn.Linear(input_dim, 16),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(16, 8),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(8,4),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(4, 1),\n",
        "            # nn.ReLU()\n",
        "\n",
        "            # nn.Linear(input_dim, 160),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(160, 80),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(80,40),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(40, 1),\n",
        "            # nn.ReLU()\n",
        "\n",
        "            # nn.Linear(input_dim, 1000),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(1000, 400),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(150, 100),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(400, 100),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(100, 50),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(50,1)\n",
        "\n",
        "            # nn.Linear(input_dim, 1024),\n",
        "            # nn.ReLU(),\n",
        "            # # nn.SiLU(),\n",
        "            # # nn.ELU(),\n",
        "            # nn.Linear(1024, 750),\n",
        "            # nn.ReLU(),\n",
        "            # # nn.SiLU(),\n",
        "            # # nn.ELU(),\n",
        "            # nn.Linear(750, 512),\n",
        "            # nn.ReLU(),\n",
        "            # # nn.SiLU(),\n",
        "            # # nn.ELU(),\n",
        "            # nn.Linear(512, 256),\n",
        "            # nn.ReLU(),\n",
        "            # # nn.SiLU(),\n",
        "            # # nn.ELU(),\n",
        "            # nn.Linear(256, 128),\n",
        "            # nn.ReLU(),\n",
        "            # # nn.SiLU(),\n",
        "            # # nn.ELU(),\n",
        "            # nn.Linear(128, 64),\n",
        "            # nn.ReLU(),\n",
        "            # # nn.SiLU(),\n",
        "            # # nn.ELU(),\n",
        "            # nn.Linear(64,1),\n",
        "            \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.squeeze(1) # (B, 1) -> (B)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5-LKF6R8xeq"
      },
      "source": [
        "# Feature Selection\n",
        "Choose features you deem useful by modifying the function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0FEnKRaIIeKp"
      },
      "outputs": [],
      "source": [
        "def select_feat(train_data, valid_data, test_data, select_all=True):\n",
        "    '''Selects useful features to perform regression'''\n",
        "    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
        "    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n",
        "\n",
        "    if select_all:\n",
        "        feat_idx = list(range(raw_x_train.shape[1]))\n",
        "    else:\n",
        "        # TODO: Select suitable feature columns.\n",
        "        feat_idx = [35,36,37,47,48,52,53,54,55,65,66,70,71,72,73,83,84]\n",
        "\n",
        "        # feat_idx = [35,36,37,47,48,53,54,55,65,66,71,72,73,83,84]\n",
        "\n",
        "        # feat_idx = [47,48,52,65,66,70,83]\n",
        "        \n",
        "        #42 is large_indoor_event        \n",
        "    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kADIPNQ2Ih5X"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k4Rq8_TztAhq"
      },
      "outputs": [],
      "source": [
        "def trainer(train_loader, valid_loader, model, config, device):\n",
        "\n",
        "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
        "\n",
        "    # Define your optimization algorithm. \n",
        "    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n",
        "    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n",
        "\n",
        "    # optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9) \n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.025, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 200, gamma=0.1, last_epoch=- 1, verbose=False)\n",
        "\n",
        "    # optimizer = torch.optim.ASGD(model.parameters(), lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0, foreach=None, maximize=False)\n",
        "\n",
        "    # optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0, foreach=None, maximize=False)\n",
        "\n",
        "    \n",
        "\n",
        "    writer = SummaryWriter() # Writer of tensoboard.\n",
        "\n",
        "    if not os.path.isdir('./models'):\n",
        "        os.mkdir('./models') # Create directory of saving models.\n",
        "\n",
        "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train() # Set your model to train mode.\n",
        "        loss_record = []\n",
        "\n",
        "        train_pbar = tqdm(train_loader, position=0, leave=False) #this is the progress bar\n",
        "\n",
        "        for x, y in train_pbar:\n",
        "            optimizer.zero_grad()               # Set gradient to zero.\n",
        "            x, y = x.to(device), y.to(device)   # Move your data to device. \n",
        "            pred = model(x)             \n",
        "            loss = criterion(pred, y)\n",
        "            loss.backward()                     # Compute gradient(backpropagation).\n",
        "            optimizer.step()                    # Update parameters.\n",
        "            step += 1\n",
        "            loss_record.append(loss.detach().item())\n",
        "            \n",
        "            # Display current epoch number and loss on tqdm progress bar.\n",
        "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
        "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
        "\n",
        "        scheduler.step() #change the lr dynamically\n",
        "\n",
        "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
        "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
        "\n",
        "        model.eval() # Set your model to evaluation mode.\n",
        "        loss_record = []\n",
        "        for x, y in valid_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                loss = criterion(pred, y)\n",
        "\n",
        "            loss_record.append(loss.item())\n",
        "            \n",
        "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
        "        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
        "\n",
        "        if mean_valid_loss < best_loss:\n",
        "            best_loss = mean_valid_loss\n",
        "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
        "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
        "            early_stop_count = 0\n",
        "        else: \n",
        "            early_stop_count += 1\n",
        "\n",
        "        if early_stop_count >= config['early_stop']:\n",
        "            print('\\nModel is not improving, so we halt the training session.')\n",
        "            return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pgkOh2e9UjE"
      },
      "source": [
        "# Configurations\n",
        "`config` contains hyper-parameters for training and the path to save your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QoWPUahCtoT6"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "config = {\n",
        "    'seed': 548769,      # Your seed number, you can pick your lucky number. :)\n",
        "    \n",
        "    'select_all': False,   # Whether to use all features.\n",
        "    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n",
        "    'n_epochs': 2500,     # Number of epochs.            \n",
        "    'batch_size': 24, \n",
        "    'learning_rate': 1e-4,              \n",
        "    'early_stop': 690,    # If model has not improved for this many consecutive epochs, stop training.     \n",
        "    'save_path': './models/model.ckpt'  # Your model will be saved here.\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrS-aJJh9XkW"
      },
      "source": [
        "# Dataloader\n",
        "Read data from files and set up training, validation, and testing sets. You do not need to modify this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-PrxU3xdpZO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jc7ZfDot2t9",
        "outputId": "8057dedb-e37f-4346-88a1-242e00e1b7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data size: (2408, 89) \n",
            "valid_data size: (601, 89) \n",
            "test_data size: (997, 88)\n",
            "number of features: 17\n"
          ]
        }
      ],
      "source": [
        "same_seed(config['seed'])\n",
        "train_data, test_data = pd.read_csv('./covid_train.csv').values, pd.read_csv('./covid_test.csv').values\n",
        "train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
        "\n",
        "# Print out the data size.\n",
        "print(f\"\"\"train_data size: {train_data.shape} \n",
        "valid_data size: {valid_data.shape} \n",
        "test_data size: {test_data.shape}\"\"\")\n",
        "\n",
        "# Select features\n",
        "x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n",
        "\n",
        "# Print out the number of features.\n",
        "print(f'number of features: {x_train.shape[1]}')\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n",
        "                                            COVID19Dataset(x_valid, y_valid), \\\n",
        "                                            COVID19Dataset(x_test)\n",
        "\n",
        "# Pytorch data loader loads pytorch dataset into batches.\n",
        "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OBYgjCA-YwD"
      },
      "source": [
        "# Start training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YdttVRkAfu2t",
        "outputId": "3b9e71c9-f4c3-4656-e31b-49732b24131b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2500]: Train loss: 23.5435, Valid loss: 4.9953\n",
            "Saving model with loss 4.995...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/2500]: Train loss: 2.1458, Valid loss: 1.3030\n",
            "Saving model with loss 1.303...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/2500]: Train loss: 1.4238, Valid loss: 1.3356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/2500]: Train loss: 1.3285, Valid loss: 2.7971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/2500]: Train loss: 1.4708, Valid loss: 1.3773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/2500]: Train loss: 1.2772, Valid loss: 1.5871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/2500]: Train loss: 1.3614, Valid loss: 2.1750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/2500]: Train loss: 1.4832, Valid loss: 1.2079\n",
            "Saving model with loss 1.208...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/2500]: Train loss: 1.2492, Valid loss: 1.9061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/2500]: Train loss: 1.5704, Valid loss: 1.7831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/2500]: Train loss: 1.2075, Valid loss: 1.6771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/2500]: Train loss: 1.3603, Valid loss: 1.5296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/2500]: Train loss: 1.4828, Valid loss: 1.8569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/2500]: Train loss: 1.4740, Valid loss: 1.5163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/2500]: Train loss: 1.2781, Valid loss: 1.0662\n",
            "Saving model with loss 1.066...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/2500]: Train loss: 1.4246, Valid loss: 3.2318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/2500]: Train loss: 1.8807, Valid loss: 1.7942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/2500]: Train loss: 1.3335, Valid loss: 1.0244\n",
            "Saving model with loss 1.024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/2500]: Train loss: 1.7837, Valid loss: 1.3966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/2500]: Train loss: 1.4029, Valid loss: 1.3783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/2500]: Train loss: 1.3161, Valid loss: 1.3058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/2500]: Train loss: 1.1075, Valid loss: 0.9398\n",
            "Saving model with loss 0.940...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/2500]: Train loss: 1.3295, Valid loss: 1.0227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/2500]: Train loss: 1.0832, Valid loss: 1.2586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/2500]: Train loss: 1.2997, Valid loss: 0.9461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/2500]: Train loss: 1.8893, Valid loss: 2.0296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/2500]: Train loss: 1.8607, Valid loss: 1.2587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/2500]: Train loss: 1.1759, Valid loss: 1.5220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/2500]: Train loss: 1.5311, Valid loss: 1.7973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/2500]: Train loss: 1.3390, Valid loss: 0.9814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/2500]: Train loss: 1.0504, Valid loss: 1.5814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/2500]: Train loss: 1.5018, Valid loss: 0.9292\n",
            "Saving model with loss 0.929...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/2500]: Train loss: 1.1031, Valid loss: 1.0661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/2500]: Train loss: 1.1932, Valid loss: 1.5229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/2500]: Train loss: 1.1482, Valid loss: 1.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/2500]: Train loss: 1.1053, Valid loss: 0.9334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/2500]: Train loss: 1.4836, Valid loss: 1.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/2500]: Train loss: 1.2018, Valid loss: 1.2861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/2500]: Train loss: 1.2747, Valid loss: 0.9083\n",
            "Saving model with loss 0.908...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/2500]: Train loss: 1.1509, Valid loss: 1.0804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/2500]: Train loss: 1.5696, Valid loss: 0.9281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/2500]: Train loss: 1.3898, Valid loss: 0.9725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/2500]: Train loss: 1.2930, Valid loss: 1.0251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/2500]: Train loss: 1.1628, Valid loss: 1.5267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/2500]: Train loss: 1.6538, Valid loss: 2.3140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/2500]: Train loss: 1.3517, Valid loss: 1.0870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/2500]: Train loss: 1.1393, Valid loss: 1.6698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/2500]: Train loss: 1.3354, Valid loss: 0.9815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/2500]: Train loss: 1.1916, Valid loss: 1.8262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/2500]: Train loss: 1.2012, Valid loss: 2.0228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-fab626c697bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMy_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put your model and data on the same computation device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-741dec26e068>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(train_loader, valid_loader, model, config, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m# Compute gradient(backpropagation).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# Update parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mloss_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             adamw(params_with_grad,\n\u001b[0m\u001b[1;32m    163\u001b[0m                   \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                   \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    220\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n",
        "trainer(train_loader, valid_loader, model, config, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik09KPqU-di-"
      },
      "source": [
        "# Plot learning curves with `tensorboard` (optional)\n",
        "\n",
        "`tensorboard` is a tool that allows you to visualize your training progress.\n",
        "\n",
        "If this block does not display your learning curve, please wait for few minutes, and re-run this block. It might take some time to load your logging information. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loA4nKmLGQ-n"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=./runs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhAHGqC9-woK"
      },
      "source": [
        "# Testing\n",
        "The predictions of your model on testing set will be stored at `pred.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5eVdpbvAlAe"
      },
      "outputs": [],
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "model = My_Model(input_dim=x_train.shape[1]).to(device)\n",
        "model.load_state_dict(torch.load(config['save_path']))\n",
        "preds = predict(test_loader, model, device) \n",
        "save_pred(preds, 'pred.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_N-wBvVahc7"
      },
      "source": [
        "# Download\n",
        "\n",
        "Run this block to download the `pred.csv` automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmMnwrHeavJv"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('pred.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ_k5rY0GvSV"
      },
      "source": [
        "# Reference\n",
        "This notebook uses code written by Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
